#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\date{}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command bibtex
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 2
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
twocolumn[
\end_layout

\begin_layout Plain Layout


\backslash
begin{@twocolumnfalse}
\end_layout

\end_inset


\end_layout

\begin_layout Title
GANDI: Generative Adversarial Networks for Detecting Irregularities
\end_layout

\begin_layout Author
Ehud Karavani
\begin_inset Newline newline
\end_inset

Adviser: Dr.
 Matan Gavish
\end_layout

\begin_layout Abstract
We present a novel methodology to apply the generative adversarial networks
 (GANs) model to the problem anomaly detection using the usually discarded
 discriminator to perform the task of detecting irregularities.
 
\end_layout

\begin_layout Standard
\begin_inset VSpace 1.2cm
\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{@twocolumnfalse} ]
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Subsection*
Generative Adversarial Networks
\end_layout

\begin_layout Standard
Generative models are models that can learn to create synthetic data that
 is similar to data that is given to them.
 Over the years, many different models tackled this problem, but recently
 one promising approach was described is Generative Adversarial Networks
 (which we abbreviate as GANs)
\begin_inset CommandInset citation
LatexCommand citep
key "goodfellow2014generative"

\end_inset

 that has dramatically sharpened the possibility of AI-generated content.
 GANs manage to skip over the difficulty of approximating many intractable
 probabilistic computations that arise in maximum likelihood related strategies
 by using an adversarial scheme, harnessing the expressiveness of neural
 networks
\begin_inset CommandInset citation
LatexCommand cite
key "goodfellow2016nips"

\end_inset

.
\end_layout

\begin_layout Standard
We do not attempt to do a complete survey of GANs, but to just simply describe
 it in a non-rigorous.
 but hopefully intuitive, description.
 A GAN model is composed of two computational components (mainly, neural
 nets) - a generator (denoted as 
\begin_inset Formula $G$
\end_inset

) and a discriminator (denoted as 
\begin_inset Formula $D$
\end_inset

).
 Given a distribution (e.g.
 a data set) that we'd like to learn (to generate more be able to generate/sampl
e more data point from) the two nets play a game.
 The generator, 
\begin_inset Formula $G$
\end_inset

, inputs a random noise seed 
\begin_inset Formula $z\sim\eta$
\end_inset

 and outputs a synthetic generated sample 
\begin_inset Formula $G\left(z\right)$
\end_inset

.
 The discriminator, 
\begin_inset Formula $D$
\end_inset

, then receives two inputs - the generated sample 
\begin_inset Formula $G\left(z\right)$
\end_inset

 and a true sample 
\begin_inset Formula $x$
\end_inset

 drawn from the true distribution 
\begin_inset Formula $P$
\end_inset

.
 It is then the job of the discriminator to be able to tell which input
 is synthetic and which is real.
 An intuitive explanation for the process of learning is that the better
 the discriminator discriminates - the better 
\begin_inset Formula $G$
\end_inset

 has to become generating samples that resembles true data, and the better
 
\begin_inset Formula $G$
\end_inset

 becomes (outputting real-like data) - the better 
\begin_inset Formula $D$
\end_inset

 has to be in discriminating between true and fake data.
\end_layout

\begin_layout Standard
If we'll attach the above with the standard cross-entropy loss for the discrimin
ator:
\begin_inset Formula 
\begin{equation}
J^{\left(D\right)}=-\frac{1}{2}\mathbb{E}_{x\sim P}\left[\log\left(D\left(x\right)\right)\right]-\frac{1}{2}\mathbb{E}_{z\sim\eta}\left[\log\left(1-D\left(G\left(z\right)\right)\right)\right]
\end{equation}

\end_inset

Then if we define the generator's loss to be:
\begin_inset Formula 
\begin{equation}
J^{\left(G\right)}=-J^{\left(D\right)}
\end{equation}

\end_inset

the competition above can be formally described as a zero-sum minimax game
 the desired parameterization for 
\begin_inset Formula $G$
\end_inset

 can be achieved by solving for:
\begin_inset Formula 
\begin{equation}
\theta^{\left(G\right)\ast}=\arg\min_{\theta^{\left(G\right)}}\max_{\theta^{\left(D\right)}}V\left(\theta^{\left(D\right)},\theta^{\left(G\right)}\right)
\end{equation}

\end_inset

Where 
\begin_inset Formula $V$
\end_inset

 is the value function and 
\begin_inset Formula $\theta^{\left(D\right)},\theta^{\left(G\right)}$
\end_inset

 are the models parameterization (i.e.
 the net's weights).
 
\end_layout

\begin_layout Standard
Under that formalization,
\emph on
 Nash equilibrium 
\emph default
is achieved in a state (under infinite computational power) the generator
 produces identical samples to the samples from the true distribution and
 the discriminator is left confused, outputting answers at random (since
 it sees two identical inputs that one is labeled with 0 and the other with
 1).
 
\end_layout

\begin_layout Standard
The framework can be visually described in 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:The-GAN-framework."

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/gan_framework.PNG
	width 100col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The GAN framework.
 Taken from 
\begin_inset CommandInset citation
LatexCommand cite
key "goodfellow2016nips"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:The-GAN-framework."

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Anomaly Detection
\end_layout

\begin_layout Standard
Anomaly detection refers to the problem of finding patterns in data that
 do not conform to a well defined notion of normal or expected behavior.
 These non-conforming patterns go by many names like anomalies, outliers,
 exceptions, to name a few, and vary dependent on the application domains.
 The goal of anomaly detection is to identify these irregular data points
 in a given sample and report them.
 Flagging out outliers is a challenging task for several reasons 
\begin_inset CommandInset citation
LatexCommand cite
key "chandola2009anomaly"

\end_inset


\end_layout

\begin_layout Enumerate
Lack of labeled data for training and validation.
\end_layout

\begin_layout Enumerate
Noisy data can be easily regarded as anomalies and it is often difficult
 to distinguish and adjust.
\end_layout

\begin_layout Enumerate
defining a normal region which encompasses every possible normal behavior
 is very difficult.
\end_layout

\begin_layout Enumerate
The exact notion of anomaly is different in different domains.
 
\end_layout

\begin_layout Enumerate
Normal behavior can be an evolving thing, and whatever learned now might
 not be sufficient for future behavior.
 
\end_layout

\begin_layout Standard
Points (1) and (2) are due to data gathering and measurement and are not
 in the scope of current work.
 We argue our method might solve for points (3) and (4), and future work
 involving reinforcement-learning in a similar framework might solve for
 (5).
 Where point (4) can be adjusted by using different NN architectures borrowed
 from the relevant domain and point (3) is the basic premise of this work.
\end_layout

\begin_layout Subsection*
The Basic Premise
\end_layout

\begin_layout Standard
As stated, the number of possible anomalies can't be accounted for.
 Thus, it is impossible to train a discriminative model to tell if a given
 datum is normally behaved or is it discordant.
 So a generative model, needs to come to the rescue, a model that knows
 the distribution 
\begin_inset Formula $P$
\end_inset

 can easily output a detectable different output when given 
\begin_inset Formula $\alpha\notin P$
\end_inset

 that will alert us that 
\begin_inset Formula $\alpha$
\end_inset

 is not an expected datum.
 This is exactly where we can harness our discriminator 
\begin_inset Formula $D$
\end_inset

.
 The hypothesis goes as such - at some point in our training, 
\begin_inset Formula $D$
\end_inset

 outputs values near 1 when encountered with true data and near 0 for data
 impersonated to the true data.
 If we could pause the training at that exact point, we would have a machinery
 that outputs ~1 for normal behavior and outputs some other value (that
 we need to know to identify and differentiate) for data that is not normally
 behaved.
 That is, we solve for challenge (3) in creating a very generalized anomaly
 detector.
\end_layout

\begin_layout Standard
Moreover, given the vast computational power that current state-of-the-art
 neural networks posses, we can solve challenge (2) by designing different
 NN for different applications.
 Since we can process image, audio, time-series and many more using NN.
 While more classical methods will probably need knowledge based transformation
 to better represent the data in order to perform, NN is agnostic about
 data preprocessing and can use their power to learn some internal representatio
n while at it.
 A similar shift occurred in the field of computer vision where hand-crafted
 preprocessed representations (such as histogram of gradients or frequency
 filtering) and classical machine learning algorithms gave away to raw inputs
 and NN.
 Thanks to NN, this 
\begin_inset Quotes eld
\end_inset

out-of-the-box
\begin_inset Quotes erd
\end_inset

 behavior, makes GANDI both powerful and easy to use, and can make the process
 of detecting of anomalies much more accessible and, hopefully, abundant.
\end_layout

\begin_layout Subsection*
Theoretical Challenges and Practical Overcomes
\end_layout

\begin_layout Standard
As stated above, all the applications of GANs known to the writer deal with
 data generation.
 That is, at the end of the training process, they discard the discriminator
 and use the generator to produce more data for their need.
 This mentality is supported by the theory, too.
 As the Nash equilibrium sentences our discriminator to life of absolute
 confusion at which its discarding seems like euthanasia.
 
\end_layout

\begin_layout Standard
Since I lack the skills to twist the theory behind the model so that our
 discriminator will win the game (discriminate immaculately) and the generator
 to lose (generate noise), I turn to the empirical process of finding that
 sweet-spot during training where the discriminator acts his best.
 I can then pause training and export (or rather metamorphose) our discriminator
 as an anomaly detector.
 This is based on the notion that the discriminator fitness is parabolic
 - it begins knowing nothing (randomly initialized) and ends up confused
 (being the generator winning the competition and thus feeding the discriminator
 with two identical inputs which are differently labeled).
 However, in between these two ends, we know it learn some meaningful representa
tion of the problem of identifying true data from false one; otherwise it
 wouldn't be able to contribute to the performance improvement of its generator
 foe - which we know to improve for sure.
 
\end_layout

\begin_layout Section*
Methods
\end_layout

\begin_layout Standard
First step is to tried the above hypothesis on a simple, easy to validate,
 easy to characterize problem.
 The toy problem chosen for the mission is a simple 1-dimensional Gaussian
 distribution.
 Gaussian distribution can be easily identifiable when learned (i.e.
 it has low entropy structure).
 The low dimension makes it easy to check, using vastly available statistical
 approaches, how good the generator is learning the true distribution.
 The choice of numerical distribution instead of a data set allows us to
 draw as many samples as needed while characterizing the learning process.
 Moreover, it allows us to easily define anomalies by specifying another
 (Gaussian) distribution with different parameters.
 The performance of the anomaly detectors can be compared with the effect
 size between the two distributions:
\begin_inset Formula 
\begin{equation}
\frac{\mu_{true}-\mu_{anomaly}}{\sigma_{true}\cdot\sigma_{anomaly}}
\end{equation}

\end_inset

As where in our case, we fix 
\begin_inset Formula $\sigma_{true}=\sigma_{anomaly}=1$
\end_inset

 and thus the effect size is only the shift in means.
\end_layout

\begin_layout Standard
Under these specifications, the hypothesis can be rephrased: Can we use
 various goodness-of-fit measurements applied to 
\begin_inset Formula $G$
\end_inset

 during training that will reveal when is it best to stop the process of
 training and say the current discriminator is the best anomaly detector
 can be achieved in the process?
\end_layout

\begin_layout Standard
To test that hypothesis, a Python framework was written using TensorFlow.
 The experiment initializes a GAN model of two neural network, different
 architectures and hyperparametrization (in both nets) were tried.
 The training process is then paused every 
\begin_inset Formula $k$
\end_inset

 steps (or otherwise specified) and it takes several measurements of the
 system.
 Mainly it tests the performance of the discriminator as an anomaly detector
 and, in addition, it performs several goodness-of-fit tests between the
 generator and the true distribution.
 The tests done were Kullback-Leibler divergence 
\begin_inset CommandInset citation
LatexCommand cite
key "kullback1951information"

\end_inset

, Kolmogorov-Smirnov statistic and Kolmogorov-Smirnov p-value 
\begin_inset CommandInset citation
LatexCommand cite
key "kolmogorov1933sulla,smirnov1948"

\end_inset

, Anderson-Darling 
\begin_inset CommandInset citation
LatexCommand cite
key "anderson1952,anderson1954"

\end_inset

, total-variation distance (
\begin_inset Formula $\ell_{1}$
\end_inset

 difference between the two cumulative density functions (CDFs)) and visual
 inspections of the CDFs, PDFs and QQ-plot (quantile-quantile plot 
\begin_inset CommandInset citation
LatexCommand cite
key "qqplot"

\end_inset

) between the generated and true distribution over time.
\end_layout

\begin_layout Standard
We tried to characterize the behavior of how these measurements correspond
 to the measurements of detection accuracy as a function of training iteration
 and the training loss progression.
 We test the performance of the anomaly detector as if it was a binary classific
ation problem, supplying it with samples from the true distribution labeled
 as 1 (corresponding the value 
\begin_inset Formula $D$
\end_inset

 tried to achieve on real samples while training) and samples from the anomaly
 distribution labeled with 0.
 We can then apply several metrics on the resulting contingency matrix and
 we mostly use the area under the curve (AUC).
\end_layout

\begin_layout Standard
To avoid generator mode collapse we equipped our discriminator with a determinis
tic 
\emph on
minibatch discrimination
\emph default
 layer that 
\begin_inset Quotes eld
\end_inset

punishes
\begin_inset Quotes erd
\end_inset

 the generator for lack of diversity.
 To assist convergence we used cross-entropy loss (rather than the min-max
 game) since gradient descent is not designed to find Nash equilibrium,
 but some low value cost function instead 
\begin_inset CommandInset citation
LatexCommand cite
key "salimans2016improved"

\end_inset

.
\end_layout

\begin_layout Section*
Results
\end_layout

\begin_layout Standard
Training converges and it seems the generator does perform better the longer
 the train goes #FIG-GIF_of_(cdf, pdf, qq)#.
 However, there is no apparent relation between the loss, the number of
 iterations and the goodness of fit statistics.
 These do improve as training progresses, but also have an oscillating behavior
 after they seem to converge Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:g_stats_loss_training"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/g_stats_over_loss_time.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The behavior of the loss and goodness-of-fit tests (top to bottom: Kolmogorov-Sm
irvov statistic, KL divergence, total variation, Anderson-Darling) during
 training.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:g_stats_loss_training"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
This lack of monotonicity in the behavior of the GAN model is, unfortunately,
 also present in 
\begin_inset Formula $D$
\end_inset

's behavior as an anomaly detector.
 When observing the AUC performance of the anomaly detector through time
 Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:ad_auc_over_time"

\end_inset

 and when observing it as a function of the various goodness-of-fit measurements
 Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:auc_over_gstat_heatmap"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/GAN_2017-08-25_11-56-32_176822-361658_9_neg-anom_auc_over_steps.png
	width 100line%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Anomaly detector shows oscillating and non-monotonic behavior as training
 progress.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:ad_auc_over_time"

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/auc_over_gstats_heatmap.png
	width 82line%
	rotateAngle 90
	rotateOrigin center

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Heatmaps presenting the performance of the anomaly detector as a function
 of the goodness-of-fit statistic measured at the same training iteration
 (y axis) and over different anomalies (x axis).
 It can be observed that there is no monotonic relation (the bright horizontal
 lines) between the anomaly detector performance and the performance of
 the generator.
 Goodness of fit statistics (clockwise): total variation, KL divergence,
 KS, Anderson-Darling.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:auc_over_gstat_heatmap"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
This non-monotonicity is shown between different effect-sized of anomalies
 as well, i.e.
 small effect-sizes having better AUC than larger effect-sizes, but these
 were rare and were solved when introducing more powerful generator net
 and providing reasonable training time.
\end_layout

\begin_layout Standard
In addition, the single-value AUC, does not capture the shape of the ROC
 curve which was sometime peculiarly shaped more as a sigmoid, rather then
 the classic over-the-diagonal Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:sigmoid_roc"

\end_inset

.
 We could not determine if this behavior is due to some computational artifact
 or due to inherent behavior of the model caused by its design (e.g.
 architecture or hyperparameters).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figs/roc_curve_sigmoid_t180000.png
	width 110col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
An example of sigmoidal ROC curve at iteration 180k.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:sigmoid_roc"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section*
Discussion
\end_layout

\begin_layout Standard
We presented a novel method for doing anomaly detection using the usually
 discarded discriminator of the GAN model.
 At its basis stands an idea for general and versatile anomaly detector.
 However, the process of achieving it relays on good intuition and somewhat
 poor theoretical assumptions and thus we turned to empirical experiments.
 We could not characterize the behavior of this model as an anomaly detector
 and could not correlate its performance to any measurable estimands.
 Specifically, we did not find it neatly correlated with the improvement
 of the generator or the the loss function.
\end_layout

\begin_layout Standard
The presented experiment can not be naturally scaled as it is not trivial
 to test for goodness-of-fit in high-dimensional data.
 This is because distance between two high-dimensional CDFs is not well
 defined unless considering all possible combinations (of dimensions) which
 makes it exponentially hard.
 One resort is to apply 
\emph on
classifier two-sample test
\emph default
 
\begin_inset CommandInset citation
LatexCommand cite
key "revisitingTwoSample"

\end_inset

 to the generated and true data; but, like high-dimensional approximations
 for KS, there is no one accepted way to do so.
\end_layout

\begin_layout Standard
The oscillator behavior of the model (in both goodness-of-fit statistics
 and loss function) might be due to the using of cross-entropy loss; were
 as a model based on a smoother loss function like Earth-Mover Distance
 (Wasserstein distance) as suggested in 
\begin_inset CommandInset citation
LatexCommand cite
key "arjovsky2017wasserstein"

\end_inset

 might produce more stable results.
 
\end_layout

\begin_layout Standard
We must remember that GAN models were derived for the sake of their generator.
 No fundamental work was done on the model's discriminator since it is always
 discarded after training.
 We hope this work can convince that there might be a good use for the discrimin
ator as well; as the say goes: one's trash is another's treasure.
\end_layout

\begin_layout Section*
Acknowledgment
\end_layout

\begin_layout Standard
The author would thanks Dr.
 Matan Gavish for his bright ideas and helpful insights through the process
 of this research.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bibliography"
options "amsplain"

\end_inset


\end_layout

\end_body
\end_document
